{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.transforms import functional as transforms\n",
    "from torchvision import models as pretrained_models\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of tutorial\n",
    "- Primitive data structures in PyTorch\n",
    "- Defining models in code\n",
    "- Loading an image file and passing it through your model\n",
    "- Using pretrained models (from PyTorch or from third parties)\n",
    "- Inspecting layer/channel/unit activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors, primitives in PyTorch\n",
    "### What does a layer of activations or an image input look like?\n",
    "![alt text](assets/alexnet.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 4])\n",
      "tensor([[[1., 1., 1., 1.],\n",
      "         [2., 2., 2., 2.]],\n",
      "\n",
      "        [[3., 3., 3., 3.],\n",
      "         [4., 4., 4., 4.]],\n",
      "\n",
      "        [[5., 5., 5., 5.],\n",
      "         [6., 6., 6., 5.]]])\n"
     ]
    }
   ],
   "source": [
    "# Tensors are just multi-dimensional matrices. Matrices are 2-dimensional (rows X columns), tensors can be more\n",
    "a = torch.tensor([[[1, 1, 1, 1], [2, 2, 2, 2]], \n",
    "                  [[3, 3, 3, 3], [4, 4, 4, 4]], \n",
    "                  [[5, 5, 5, 5], [6, 6, 6, 5]]], \n",
    "                 dtype=torch.float32)\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor c is:\n",
      "tensor([[[2., 2., 2., 2.],\n",
      "         [3., 3., 3., 3.]],\n",
      "\n",
      "        [[4., 4., 4., 4.],\n",
      "         [5., 5., 5., 5.]],\n",
      "\n",
      "        [[6., 6., 6., 6.],\n",
      "         [7., 7., 7., 6.]]])\n",
      "Tensor d is:\n",
      "tensor([[[5.5000, 5.5000, 5.5000, 5.5000],\n",
      "         [6.0000, 6.0000, 6.0000, 6.0000]],\n",
      "\n",
      "        [[6.5000, 6.5000, 6.5000, 6.5000],\n",
      "         [7.0000, 7.0000, 7.0000, 7.0000]],\n",
      "\n",
      "        [[7.5000, 7.5000, 7.5000, 7.5000],\n",
      "         [8.0000, 8.0000, 8.0000, 7.5000]]])\n",
      "Tensor e is:\n",
      "tensor([[2., 2., 2.],\n",
      "        [4., 4., 4.],\n",
      "        [6., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# You can perform math on tensors just like with ordinary numbers or matrices\n",
    "b = torch.ones(size=a.shape, dtype=a.dtype)\n",
    "c = a + b\n",
    "print('Tensor c is:\\n{}'.format(c))\n",
    "\n",
    "# You can also use scalars on your tensors\n",
    "d = a / 2 + 5\n",
    "print('Tensor d is:\\n{}'.format(d))\n",
    "\n",
    "# You can grab slices along different dimensions\n",
    "e = a[:, 1, 0:3]    # Everything along the first dimension, second slice of the second dimension, slices 1,2,3 of the third dimension\n",
    "print('Tensor e is:\\n{}'.format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's what the tensor would look like for an RGB image of height=128 and width=256 initialized with\n",
    "# random pixels in the range [0-1]\n",
    "image_tensor = torch.rand(size=(3, 128, 256))     # [channels X height X width] (same structure for conv layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining models in code\n",
    "\n",
    "### 3 steps:\n",
    "1. Create a subclass of `nn.Module`\n",
    "1. Define layers/parameters in `__init__()`\n",
    "2. Define connections between layers mapping inputs to outputs in `forward()`\n",
    "\n",
    "![alt text](assets/alexnet.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model class\n",
    "class TinyCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_channels, n_classes):    # Can take all the arguments you want\n",
    "        super().__init__()                            # Always need to initialize the superclass!!!\n",
    "        \n",
    "        # Use the nn module to create all of your layers\n",
    "        self.conv_1 = nn.Conv2d(input_channels, 96, kernel_size=11, stride=4)  # Conv layer with initialized params\n",
    "        self.relu_1 = nn.ReLU(inplace=True)                                    # ReLU nonlinearity\n",
    "        self.maxpool_1 = nn.MaxPool2d(kernel_size=3, stride=2)                 # Reduce resolution\n",
    "        self.conv_2 = nn.Conv2d(96, 256, kernel_size=5)\n",
    "        self.relu_2 = nn.ReLU(inplace=True)\n",
    "        self.maxpool_2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.adaptive_maxpool = nn.AdaptiveMaxPool2d(output_size=1)            # Collapse height/width completely\n",
    "        self.fc_1 = nn.Linear(256, 100)                                        # 256 units -> 100 units\n",
    "        self.fc_relu = nn.ReLU(inplace=True)\n",
    "        self.fc_2 = nn.Linear(100, n_classes)\n",
    "        \n",
    "    def forward(self, input):               # Define how inputs pass through your network from layer to layer\n",
    "        # Pass the input through all of the convolutional/relu/pooling layers\n",
    "        x = self.conv_1(input)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.maxpool_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.relu_2(x)\n",
    "        x = self.maxpool_2(x)\n",
    "        \n",
    "        # Collapse the height/width layers and get rid of them to make this a single-dimensional layer (vector)\n",
    "        x = self.adaptive_maxpool(x)        # [batches X channels X height X width] -> [batches X channels X 1 X 1]\n",
    "        x = x.view(x.shape[0], -1)          # [batches X channels X 1 X 1] -> [batches X channels]\n",
    "        \n",
    "        # Pass the features through the linear/relu layers\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_relu(x)\n",
    "        x = self.fc_2(x)\n",
    "        \n",
    "        # Your model doesn't have to be a statically connected series of layers; you can have any arbitrary\n",
    "        # Python code in the `forward` function. Here, if the model is not being trained, we convert the\n",
    "        # outputs to a probability distribution over classes (i.e. make them sum to 1)\n",
    "        if not self.training:\n",
    "            x = F.softmax(x, dim=1)\n",
    "        \n",
    "        # Return the output of the network\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyCNN(\n",
      "  (conv_1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "  (relu_1): ReLU(inplace=True)\n",
      "  (maxpool_1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv_2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu_2): ReLU(inplace=True)\n",
      "  (maxpool_2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (adaptive_maxpool): AdaptiveMaxPool2d(output_size=1)\n",
      "  (fc_1): Linear(in_features=256, out_features=100, bias=True)\n",
      "  (fc_relu): ReLU(inplace=True)\n",
      "  (fc_2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate an instance of the model\n",
    "model = TinyCNN(input_channels=3, n_classes=10)\n",
    "model.eval()     # Whenever we're not training, model should be in evaluation mode\n",
    "print(model)\n",
    "\n",
    "# Put the model on the GPU, if one is available\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading an image file and passing it through your model\n",
    "\n",
    "### 3 steps:\n",
    "1. Open the image using the Pillow (PIL) python package\n",
    "2. Preprocess the image to a format your model expects (resolution, centre crop, etc.)\n",
    "3. Convert the image to a PyTorch tensor\n",
    "4. Normalize the tensor's range of values to be the same as during training ([0 - 1], [-1 - 1], etc.)\n",
    "5. Pass the tensor to your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=800x572 at 0x7FD91B719310>\n"
     ]
    }
   ],
   "source": [
    "# Load image\n",
    "image = Image.open('assets/dog.jpg')\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=224x224 at 0x7FD91CB20450>\n"
     ]
    }
   ],
   "source": [
    "# Preprocess image\n",
    "image = transforms.center_crop(image, (572, 572))    # Use a square aspect ratio for this model\n",
    "image = transforms.resize(image, (224, 224))         # Lower the resolution (faster computation)\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Convert image to tensor and normalize to imagenet mean and standard deviation\n",
    "image_tensor = transforms.to_tensor(image)                                       # Pixels ranges [0 - 1]\n",
    "image_tensor = transforms.normalize(image_tensor, mean=(0.485, 0.456, 0.406),    # Normalize to ImageNet range\n",
    "                                    std=(0.229, 0.224, 0.225))\n",
    "print(image_tensor.shape)\n",
    "\n",
    "# Put the image_tensor input on the GPU, if one is available\n",
    "if torch.cuda.is_available():\n",
    "    image_tensor = image_tensor.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "tensor(1.0000, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Now, our image is in a data format that our model can handle, and we can get the model's output\n",
    "image_tensor_batch = image_tensor.unsqueeze(dim=0)              # [C X H X W] -> [1 X C X H X W] (batch dimension)\n",
    "class_probabilities_batch = model(image_tensor_batch)\n",
    "class_probabilities = class_probabilities_batch.squeeze(dim=0)  # [1 X n_classes] -> [n_classes]\n",
    "print(class_probabilities.shape)\n",
    "print(class_probabilities.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pretrained models\n",
    "\n",
    "### The Torchvision module provides many commonly used pretrained models, and people online often make their model code + trained parameters available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Let's load a pretrained AlexNet and see what's inside\n",
    "model = pretrained_models.alexnet(pretrained=True)\n",
    "model.eval()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most probable class is 217 with \"probability\" 0.3000657558441162\n"
     ]
    }
   ],
   "source": [
    "# We can try this pretrained AlexNet on the exact same image that we had before.\n",
    "# The image is of a dog, so hopefully the class with the highest probability should be one too\n",
    "class_probabilities = model(image_tensor.unsqueeze(0)).squeeze(0)\n",
    "class_probabilities = F.softmax(class_probabilities, dim=0)         # PyTorch AlexNet skipped this layer\n",
    "max_prob, max_class_idx = class_probabilities.max(dim=0)\n",
    "max_prob, max_class_idx = max_prob.item(), max_class_idx.item()     # Convert 0d tensors to Python primitives\n",
    "print('Most probable class is {} with \"probability\" {}'.format(max_class_idx, max_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ImageNet class 916 corresponds to \"web site, website, internet site, site\"... Let's see if the model does better when we show it an image from the ImageNet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most probable class is 247 with \"probability\" 0.982213020324707\n"
     ]
    }
   ],
   "source": [
    "# Load the image, preprocess it, and convert it to a tensor with the model's trained range of values\n",
    "image = Image.open('assets/imagenet_dog.jpg')\n",
    "image = transforms.resize(image, (224, 224))\n",
    "image_tensor = transforms.to_tensor(image)\n",
    "image_tensor = transforms.normalize(image_tensor, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "\n",
    "# Get the model's predictions\n",
    "class_probabilities = model(image_tensor.unsqueeze(0)).squeeze(0)\n",
    "class_probabilities = F.softmax(class_probabilities, dim=0)         # PyTorch AlexNet skipped this layer\n",
    "max_prob, max_class_idx = class_probabilities.max(dim=0)\n",
    "max_prob, max_class_idx = max_prob.item(), max_class_idx.item()     # Convert 0d tensors to Python primitives\n",
    "print('Most probable class is {} with \"probability\" {}'.format(max_class_idx, max_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class 247 is \"Saint Bernard, St Bernard\". Makes a little more sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting layer/channel/unit activations\n",
    "\n",
    "### The way I do it is I write a model class, give it the pre-trained model's weights, and just return the layer/channel/unit I need. There may be other ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNetConv3(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        alexnet_pretrained = pretrained_models.alexnet(pretrained=True)\n",
    "        self.features = alexnet_pretrained.features[:8]     # Grab the first 8 features layers of AlexNet (conv3)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        conv3 = self.features(input)          # [batch_size X 384 X height X width]\n",
    "        conv3_channel4 = conv3[:, 3]          # [batch_size X height X width]. Same as conv3[:, 3, :, :]\n",
    "        conv3_channel4_unith5w2 = conv3_channel4[:, 4, 1]       # [batch_size]\n",
    "        return conv3, conv3_channel4, conv3_channel4_unith5w2   # Just returning all 3 to show how to do each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([384, 13, 13])\n",
      "torch.Size([13, 13])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = AlexNetConv3()\n",
    "model.eval()\n",
    "\n",
    "# Get the intended layers/channels/units of the model for our dog image\n",
    "conv3, conv3_channel4, conv3_channel4_unith5w2 = model(image_tensor.unsqueeze(dim=0))\n",
    "conv3, conv3_channel4, conv3_channel4_unith5w2 = conv3.squeeze(dim=0), conv3_channel4.squeeze(dim=0), conv3_channel4_unith5w2.squeeze(dim=0)\n",
    "\n",
    "print(conv3.shape)\n",
    "print(conv3_channel4.shape)\n",
    "print(conv3_channel4_unith5w2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can save our model's parameters like so (usually done after training)\n",
    "model_serialized_params = model.state_dict()\n",
    "torch.save(model_serialized_params, 'assets/saved_alexnet_pretrained.pth')\n",
    "\n",
    "# And similarly load our model. For this, we need to instantiate an instance of the model class\n",
    "# and then load the .pth parameters. When you find code online, they will always provide the model class.\n",
    "# Sometimes, they may also provide the trained parameters as well.\n",
    "model_serialized_params = torch.load('assets/saved_alexnet_pretrained.pth',\n",
    "                                    map_location=lambda storage, loc: storage)    # Load regardless of if it was saved on CPU or GPU\n",
    "model.load_state_dict(model_serialized_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "I hope this has been helpful. There is obviously much more to PyTorch than what we've convered here. In the rest\n",
    "of the repository, you'll find code showing how to:\n",
    "- Train a custom model for classification\n",
    "- Fine-tune a pretrained model\n",
    "- Evaluate a model\n",
    "- Make a dataset class for your training/evaluation pipeline\n",
    "- Log training curves to the console and plot them using TensorboardX\n",
    "\n",
    "Of course, I can't show everything, but rest assured that PyTorch has plenty of easy-to-use code, and we've only scratched the surface.\n",
    "- Tensor operations (can do much more than just +-*/ tensors together)\n",
    "- Neural network layers (very rare that you'll ever have to write your own)\n",
    "- Loss functions\n",
    "- Stochastic Gradient Descent-based optimizers\n",
    "\n",
    "And, the best thing about PyTorch, there is plenty of code online which is all relatively modular and easy to understand when compared to other machine learning frameworks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
